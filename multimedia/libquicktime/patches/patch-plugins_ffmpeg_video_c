Deal with newer FFmpeg API.

Index: plugins/ffmpeg/video.c
--- plugins/ffmpeg/video.c.orig
+++ plugins/ffmpeg/video.c
@@ -37,10 +37,10 @@
 #endif
 
 
-#ifdef  PIX_FMT_YUV422P10
-#define PIX_FMT_YUV422P10_OR_DUMMY PIX_FMT_YUV422P10
+#ifdef  AV_PIX_FMT_YUV422P10
+#define AV_PIX_FMT_YUV422P10_OR_DUMMY AV_PIX_FMT_YUV422P10
 #else
-#define PIX_FMT_YUV422P10_OR_DUMMY -1234
+#define AV_PIX_FMT_YUV422P10_OR_DUMMY -1234
 #endif
 
 #if LIBAVCODEC_VERSION_INT >= ((54<<16)|(1<<8)|0)
@@ -90,9 +90,9 @@ typedef struct
   int imx_bitrate;
   int imx_strip_vbi;
 
-  /* In some cases FFMpeg would report something like PIX_FMT_YUV422P, while
-     we would like to treat it as PIX_FMT_YUVJ422P. It's only used for decoding */
-  enum PixelFormat reinterpret_pix_fmt;
+  /* In some cases FFMpeg would report something like AV_PIX_FMT_YUV422P, while
+     we would like to treat it as AV_PIX_FMT_YUVJ422P. It's only used for decoding */
+  enum AVPixelFormat reinterpret_pix_fmt;
   
   int is_imx;
   int y_offset;
@@ -137,42 +137,42 @@ typedef struct
 
 static const struct
   {
-  enum PixelFormat ffmpeg_id;
+  enum AVPixelFormat ffmpeg_id;
   int              lqt_id;
   int              exact;
   }
 colormodels[] =
   {
-    { PIX_FMT_YUV420P,   BC_YUV420P,   1 }, ///< Planar YUV 4:2:0 (1 Cr & Cb sample per 2x2 Y samples)
+    { AV_PIX_FMT_YUV420P,   BC_YUV420P,   1 }, ///< Planar YUV 4:2:0 (1 Cr & Cb sample per 2x2 Y samples)
 #if LIBAVUTIL_VERSION_INT < (50<<16)
-    { PIX_FMT_YUV422,    BC_YUV422,    1 },
+    { AV_PIX_FMT_YUV422,    BC_YUV422,    1 },
 #else
-    { PIX_FMT_YUYV422,   BC_YUV422,    1 },
+    { AV_PIX_FMT_YUYV422,   BC_YUV422,    1 },
 #endif
-    { PIX_FMT_RGB24,     BC_RGB888,    1 }, ///< Packed pixel, 3 bytes per pixel, RGBRGB...
-    { PIX_FMT_BGR24,     BC_BGR888,    1 }, ///< Packed pixel, 3 bytes per pixel, BGRBGR...
-    { PIX_FMT_YUV422P,   BC_YUV422P,   1 }, ///< Planar YUV 4:2:2 (1 Cr & Cb sample per 2x1 Y samples)
-    { PIX_FMT_YUV444P,   BC_YUV444P,   1 }, ///< Planar YUV 4:4:4 (1 Cr & Cb sample per 1x1 Y samples)
-    { PIX_FMT_YUV411P,   BC_YUV411P,   1 }, ///< Planar YUV 4:1:1 (1 Cr & Cb sample per 4x1 Y samples)
-    { PIX_FMT_YUV422P16, BC_YUV422P16, 1 }, ///< Planar 16 bit YUV 4:2:2 (1 Cr & Cb sample per 2x1 Y samples)
-#ifdef PIX_FMT_YUV422P10
-    { PIX_FMT_YUV422P10, BC_YUV422P10, 1 }, ///< 10 bit samples in uint16_t containers, planar 4:2:2
+    { AV_PIX_FMT_RGB24,     BC_RGB888,    1 }, ///< Packed pixel, 3 bytes per pixel, RGBRGB...
+    { AV_PIX_FMT_BGR24,     BC_BGR888,    1 }, ///< Packed pixel, 3 bytes per pixel, BGRBGR...
+    { AV_PIX_FMT_YUV422P,   BC_YUV422P,   1 }, ///< Planar YUV 4:2:2 (1 Cr & Cb sample per 2x1 Y samples)
+    { AV_PIX_FMT_YUV444P,   BC_YUV444P,   1 }, ///< Planar YUV 4:4:4 (1 Cr & Cb sample per 1x1 Y samples)
+    { AV_PIX_FMT_YUV411P,   BC_YUV411P,   1 }, ///< Planar YUV 4:1:1 (1 Cr & Cb sample per 4x1 Y samples)
+    { AV_PIX_FMT_YUV422P16, BC_YUV422P16, 1 }, ///< Planar 16 bit YUV 4:2:2 (1 Cr & Cb sample per 2x1 Y samples)
+#ifdef AV_PIX_FMT_YUV422P10
+    { AV_PIX_FMT_YUV422P10, BC_YUV422P10, 1 }, ///< 10 bit samples in uint16_t containers, planar 4:2:2
 #endif
-    { PIX_FMT_RGB565,    BC_RGB565,    1 }, ///< always stored in cpu endianness
-    { PIX_FMT_YUVJ420P,  BC_YUVJ420P,  1 }, ///< Planar YUV 4:2:0 full scale (jpeg)
-    { PIX_FMT_YUVJ422P,  BC_YUVJ422P,  1 }, ///< Planar YUV 4:2:2 full scale (jpeg)
-    { PIX_FMT_YUVJ444P,  BC_YUVJ444P,  1 }, ///< Planar YUV 4:4:4 full scale (jpeg)
+    { AV_PIX_FMT_RGB565,    BC_RGB565,    1 }, ///< always stored in cpu endianness
+    { AV_PIX_FMT_YUVJ420P,  BC_YUVJ420P,  1 }, ///< Planar YUV 4:2:0 full scale (jpeg)
+    { AV_PIX_FMT_YUVJ422P,  BC_YUVJ422P,  1 }, ///< Planar YUV 4:2:2 full scale (jpeg)
+    { AV_PIX_FMT_YUVJ444P,  BC_YUVJ444P,  1 }, ///< Planar YUV 4:4:4 full scale (jpeg)
 #if LIBAVUTIL_VERSION_INT < (50<<16)
-    { PIX_FMT_RGBA32,    BC_RGBA8888,  0 }, ///< Packed pixel, 4 bytes per pixel, BGRABGRA...
+    { AV_PIX_FMT_RGBA32,    BC_RGBA8888,  0 }, ///< Packed pixel, 4 bytes per pixel, BGRABGRA...
 #else
-    { PIX_FMT_RGB32,     BC_RGBA8888,  0 }, ///< Packed pixel, 4 bytes per pixel, BGRABGRA...
+    { AV_PIX_FMT_RGB32,     BC_RGBA8888,  0 }, ///< Packed pixel, 4 bytes per pixel, BGRABGRA...
 #endif
-    { PIX_FMT_RGB555,    BC_RGB888,    0 }, ///< always stored in cpu endianness, most significant bit to 1
-    { PIX_FMT_GRAY8,     BC_RGB888,    0 },
-    { PIX_FMT_MONOWHITE, BC_RGB888,    0 }, ///< 0 is white
-    { PIX_FMT_MONOBLACK, BC_RGB888,    0 }, ///< 0 is black
-    { PIX_FMT_PAL8,      BC_RGB888,    0 }, ///< 8 bit with RGBA palette
-    { PIX_FMT_YUV410P,   BC_YUV420P,   0 }, ///< Planar YUV 4:1:0 (1 Cr & Cb sample per 4x4 Y samples)
+    { AV_PIX_FMT_RGB555,    BC_RGB888,    0 }, ///< always stored in cpu endianness, most significant bit to 1
+    { AV_PIX_FMT_GRAY8,     BC_RGB888,    0 },
+    { AV_PIX_FMT_MONOWHITE, BC_RGB888,    0 }, ///< 0 is white
+    { AV_PIX_FMT_MONOBLACK, BC_RGB888,    0 }, ///< 0 is black
+    { AV_PIX_FMT_PAL8,      BC_RGB888,    0 }, ///< 8 bit with RGBA palette
+    { AV_PIX_FMT_YUV410P,   BC_YUV420P,   0 }, ///< Planar YUV 4:1:0 (1 Cr & Cb sample per 4x4 Y samples)
   };
 
 static const struct
@@ -343,16 +343,16 @@ static int lqt_tenbit_dnxhd_supported(AVCodec const* c
   if (!codec->pix_fmts)
     return 0;
 
-  for (i = 0; codec->pix_fmts[i] != PIX_FMT_NONE; ++i)
+  for (i = 0; codec->pix_fmts[i] != AV_PIX_FMT_NONE; ++i)
     {
-    if (codec->pix_fmts[i] == PIX_FMT_YUV422P10_OR_DUMMY)
+    if (codec->pix_fmts[i] == AV_PIX_FMT_YUV422P10_OR_DUMMY)
       return 1;
     }
 
   return 0;
   }
 
-static enum PixelFormat lqt_ffmpeg_get_ffmpeg_colormodel(int id)
+static enum AVPixelFormat lqt_ffmpeg_get_ffmpeg_colormodel(int id)
   {
   int i;
 
@@ -361,10 +361,10 @@ static enum PixelFormat lqt_ffmpeg_get_ffmpeg_colormod
     if(colormodels[i].lqt_id == id)
       return colormodels[i].ffmpeg_id;
     }
-  return PIX_FMT_NB;
+  return AV_PIX_FMT_NB;
   }
 
-static int lqt_ffmpeg_get_lqt_colormodel(enum PixelFormat id, int * exact)
+static int lqt_ffmpeg_get_lqt_colormodel(enum AVPixelFormat id, int * exact)
   {
   int i;
 
@@ -400,26 +400,26 @@ static void lqt_ffmpeg_setup_decoding_colormodel(quick
   codec->reinterpret_pix_fmt = codec->avctx->pix_fmt;
 
   /* First we try codec-specific colormodel matching. */
-  if(codec->decoder->id == CODEC_ID_DNXHD)
+  if(codec->decoder->id == AV_CODEC_ID_DNXHD)
     {
-    /* FFMpeg supports PIX_FMT_YUV422P and PIX_FMT_YUV422P10 for DNxHD, which
-       we sometimes interpret as PIX_FMT_YUVJ422P and PIX_FMT_YUVJ422P10. */
-    if (codec->avctx->pix_fmt == PIX_FMT_YUV422P || codec->avctx->pix_fmt == PIX_FMT_YUV422P10_OR_DUMMY)
+    /* FFMpeg supports AV_PIX_FMT_YUV422P and AV_PIX_FMT_YUV422P10 for DNxHD, which
+       we sometimes interpret as AV_PIX_FMT_YUVJ422P and AV_PIX_FMT_YUVJ422P10. */
+    if (codec->avctx->pix_fmt == AV_PIX_FMT_YUV422P || codec->avctx->pix_fmt == AV_PIX_FMT_YUV422P10_OR_DUMMY)
       {
-      int p10 = (codec->avctx->pix_fmt == PIX_FMT_YUV422P10_OR_DUMMY);
+      int p10 = (codec->avctx->pix_fmt == AV_PIX_FMT_YUV422P10_OR_DUMMY);
       *exact = 1;
       if (lqt_ffmpeg_get_avid_yuv_range(vtrack->track) == AVID_FULL_YUV_RANGE)
         {
         vtrack->stream_cmodel = p10 ? BC_YUVJ422P10 : BC_YUVJ422P;
-        codec->reinterpret_pix_fmt = p10 ? PIX_FMT_YUV422P10_OR_DUMMY : PIX_FMT_YUVJ422P;
-        // Note: reinterpret_pix_fmt should really be PIX_FMT_YUVJ422P10, except
+        codec->reinterpret_pix_fmt = p10 ? AV_PIX_FMT_YUV422P10_OR_DUMMY : AV_PIX_FMT_YUVJ422P;
+        // Note: reinterpret_pix_fmt should really be AV_PIX_FMT_YUVJ422P10, except
         // there is no such colormodel in FFMpeg. Fortunately, it's not a problem
         // in this case, as reinterpret_pix_fmt is only used when *exact == 0.
         }
       else
         {
         vtrack->stream_cmodel = p10 ? BC_YUV422P10 : BC_YUV422P;
-        codec->reinterpret_pix_fmt = p10 ? PIX_FMT_YUV422P10_OR_DUMMY : PIX_FMT_YUV422P;
+        codec->reinterpret_pix_fmt = p10 ? AV_PIX_FMT_YUV422P10_OR_DUMMY : AV_PIX_FMT_YUV422P;
         }
       return;
       }
@@ -438,16 +438,16 @@ static void lqt_ffmpeg_setup_encoding_colormodel(quick
   quicktime_ffmpeg_video_codec_t *codec = vtrack->codec->priv;
   codec->avctx->pix_fmt = lqt_ffmpeg_get_ffmpeg_colormodel(vtrack->stream_cmodel);
 
-  if (codec->encoder->id == CODEC_ID_DNXHD)
+  if (codec->encoder->id == AV_CODEC_ID_DNXHD)
     {
-    /* FFMpeg's DNxHD encoder only supports PIX_FMT_YUV422P and PIX_FMT_YUV422P10
-       and doesn't know anything about PIX_FMT_YUVJ422P and PIX_FMT_YUVJ422P10
+    /* FFMpeg's DNxHD encoder only supports AV_PIX_FMT_YUV422P and AV_PIX_FMT_YUV422P10
+       and doesn't know anything about AV_PIX_FMT_YUVJ422P and AV_PIX_FMT_YUVJ422P10
        (in fact, the latter doesn't even exist) */
-    codec->avctx->pix_fmt = PIX_FMT_YUV422P;
+    codec->avctx->pix_fmt = AV_PIX_FMT_YUV422P;
     if (vtrack->stream_cmodel == BC_YUV422P10 || vtrack->stream_cmodel == BC_YUVJ422P10)
       {
       if (lqt_tenbit_dnxhd_supported(codec->encoder))
-        codec->avctx->pix_fmt = PIX_FMT_YUV422P10_OR_DUMMY;
+        codec->avctx->pix_fmt = AV_PIX_FMT_YUV422P10_OR_DUMMY;
       }
     }
   }
@@ -458,7 +458,7 @@ static void lqt_ffmpeg_setup_encoding_colormodel(quick
 /* From avcodec.h: */
 
 /*
- * PIX_FMT_RGBA32 is handled in an endian-specific manner. A RGBA
+ * AV_PIX_FMT_RGBA32 is handled in an endian-specific manner. A RGBA
  * color is put together as:
  *  (A << 24) | (R << 16) | (G << 8) | B
  * This is stored as BGRA on little endian CPU architectures and ARGB on
@@ -530,7 +530,7 @@ static void convert_rgba_to_argb(uint8_t const* src, i
  */
 
 static void convert_image_decode(quicktime_ffmpeg_video_codec_t *codec,
-                                 AVFrame * in_frame, enum PixelFormat in_format,
+                                 AVFrame * in_frame, enum AVPixelFormat in_format,
                                  unsigned char ** out_frame, int out_format,
                                  int width, int height, int row_span, int row_span_uv)
   {
@@ -547,9 +547,9 @@ static void convert_image_decode(quicktime_ffmpeg_vide
    *  RGBA format like in ffmpeg??
    */
 #if LIBAVUTIL_VERSION_INT < (50<<16)
-  if((in_format == PIX_FMT_RGBA32) && (out_format == BC_RGBA8888))
+  if((in_format == AV_PIX_FMT_RGBA32) && (out_format == BC_RGBA8888))
 #else
-    if((in_format == PIX_FMT_RGB32) && (out_format == BC_RGBA8888))
+    if((in_format == AV_PIX_FMT_RGB32) && (out_format == BC_RGBA8888))
 #endif
       {
       convert_image_decode_rgba(in_frame, out_frame, width, height, codec->y_offset);
@@ -728,13 +728,13 @@ static int lqt_ffmpeg_decode_video(quicktime_t *file, 
 
     /* Set extradata: It's done differently for each codec */
 
-    if(codec->decoder->id == CODEC_ID_SVQ3)
+    if(codec->decoder->id == AV_CODEC_ID_SVQ3)
       {
       extradata       = trak->mdia.minf.stbl.stsd.table[0].table_raw + 4;
       extradata_size  = trak->mdia.minf.stbl.stsd.table[0].table_raw_size - 4;
       
       }
-    else if(codec->decoder->id == CODEC_ID_H264)
+    else if(codec->decoder->id == AV_CODEC_ID_H264)
       {
       user_atom = quicktime_stsd_get_user_atom(trak, "avcC", &user_atom_len);
 
@@ -753,7 +753,7 @@ static int lqt_ffmpeg_decode_video(quicktime_t *file, 
         }
       
       }
-    else if(codec->decoder->id == CODEC_ID_MPEG4)
+    else if(codec->decoder->id == AV_CODEC_ID_MPEG4)
       {
       if(trak->mdia.minf.stbl.stsd.table[0].has_esds)
         {
@@ -781,7 +781,7 @@ static int lqt_ffmpeg_decode_video(quicktime_t *file, 
     if(extradata)
       {
       codec->extradata =
-        calloc(1, extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);
+        calloc(1, extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
       memcpy(codec->extradata, extradata, extradata_size);
       codec->avctx->extradata_size = extradata_size;
       codec->avctx->extradata = codec->extradata;
@@ -829,7 +829,7 @@ static int lqt_ffmpeg_decode_video(quicktime_t *file, 
     if(avcodec_open2(codec->avctx, codec->decoder, NULL) != 0)
       return -1;
 #endif
-    codec->frame = avcodec_alloc_frame();
+    codec->frame = av_frame_alloc();
     vtrack->stream_cmodel = LQT_COLORMODEL_NONE;
     codec->initialized = 1;
     }
@@ -929,10 +929,10 @@ static int lqt_ffmpeg_decode_video(quicktime_t *file, 
 #ifdef HAVE_LIBSWSCALE
 
 #if LIBAVUTIL_VERSION_INT < (50<<16)
-      if(!((codec->avctx->pix_fmt == PIX_FMT_RGBA32) &&
+      if(!((codec->avctx->pix_fmt == AV_PIX_FMT_RGBA32) &&
            (vtrack->stream_cmodel == BC_RGBA8888)))
 #else
-        if(!((codec->avctx->pix_fmt == PIX_FMT_RGB32) &&
+        if(!((codec->avctx->pix_fmt == AV_PIX_FMT_RGB32) &&
              (vtrack->stream_cmodel == BC_RGBA8888)))
 #endif
           {
@@ -947,15 +947,15 @@ static int lqt_ffmpeg_decode_video(quicktime_t *file, 
           }
 #endif
       }
-    if(codec->decoder->id == CODEC_ID_DVVIDEO)
+    if(codec->decoder->id == AV_CODEC_ID_DVVIDEO)
       {
       if(vtrack->stream_cmodel == BC_YUV420P)
         vtrack->chroma_placement = LQT_CHROMA_PLACEMENT_DVPAL;
       vtrack->interlace_mode = LQT_INTERLACE_BOTTOM_FIRST;
       vtrack->ci.id = LQT_COMPRESSION_DV;
       }
-    else if((codec->decoder->id == CODEC_ID_MPEG4) ||
-            (codec->decoder->id == CODEC_ID_H264))
+    else if((codec->decoder->id == AV_CODEC_ID_MPEG4) ||
+            (codec->decoder->id == AV_CODEC_ID_H264))
       {
       if(vtrack->stream_cmodel == BC_YUV420P)
         vtrack->chroma_placement = LQT_CHROMA_PLACEMENT_MPEG2;
@@ -1140,8 +1140,8 @@ static int init_imx_encoder(quicktime_t *file, int tra
   codec->avctx->qmin = 1;
   codec->avctx->qmax = 3;
   codec->avctx->rtp_payload_size = 1; // ??
-  codec->avctx->rc_buffer_aggressivity = 0.25;
-  codec->avctx->flags |= CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_LOW_DELAY;
+  av_dict_set(&codec->options, "rc_buf_aggressivity", "0.25", 0);
+  codec->avctx->flags |= AV_CODEC_FLAG_INTERLACED_DCT|AV_CODEC_FLAG_LOW_DELAY;
 
 #if (LIBAVCODEC_VERSION_MAJOR < 54)
   codec->avctx->flags2 |= CODEC_FLAG2_INTRA_VLC|CODEC_FLAG2_NON_LINEAR_QUANT;
@@ -1299,13 +1299,13 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
     {
     if(vtrack->stream_cmodel == BC_YUV420P)
       {
-      if(codec->encoder->id == CODEC_ID_MPEG4)
+      if(codec->encoder->id == AV_CODEC_ID_MPEG4)
         {
         vtrack->chroma_placement = LQT_CHROMA_PLACEMENT_MPEG2;
         /* enable interlaced encoding */
         vtrack->interlace_mode = LQT_INTERLACE_NONE;
         }
-      else if(codec->encoder->id == CODEC_ID_DVVIDEO)
+      else if(codec->encoder->id == AV_CODEC_ID_DVVIDEO)
         {
         vtrack->chroma_placement = LQT_CHROMA_PLACEMENT_DVPAL;
         }
@@ -1318,7 +1318,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
         
   if(!codec->initialized)
     {
-    codec->frame = avcodec_alloc_frame();
+    codec->frame = av_frame_alloc();
 
     /* time_base is 1/framerate for constant framerate */
           
@@ -1328,7 +1328,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
     //          codec->avctx->time_base.den = 1;
     //          codec->avctx->time_base.num = lqt_video_time_scale(file, track);
 
-    if(codec->avctx->flags & CODEC_FLAG_QSCALE)
+    if(codec->avctx->flags & AV_CODEC_FLAG_QSCALE)
       codec->avctx->global_quality = codec->qscale;
                               
     codec->avctx->width = width;
@@ -1340,11 +1340,11 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
     codec->avctx->sample_aspect_ratio.num = pixel_width;
     codec->avctx->sample_aspect_ratio.den = pixel_height;
     /* Use global headers for mp4v */
-    if(codec->encoder->id == CODEC_ID_MPEG4)
+    if(codec->encoder->id == AV_CODEC_ID_MPEG4)
       {
       if(!(file->file_type & (LQT_FILE_AVI|LQT_FILE_AVI_ODML)))
         {
-        codec->avctx->flags |= CODEC_FLAG_GLOBAL_HEADER;
+        codec->avctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
         codec->write_global_header = 1;
         }
             
@@ -1360,16 +1360,16 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
         {
         lqt_log(file, LQT_LOG_INFO, LOG_DOMAIN, "Enabling interlaced encoding");
         codec->avctx->flags |=
-          (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME|CODEC_FLAG_ALT_SCAN);
+          (AV_CODEC_FLAG_INTERLACED_DCT|AV_CODEC_FLAG_INTERLACED_ME|AV_CODEC_FLAG_ALT_SCAN);
         }
 #endif
       }
-    else if((codec->encoder->id == CODEC_ID_MSMPEG4V3) && (trak->strl) &&
+    else if((codec->encoder->id == AV_CODEC_ID_MSMPEG4V3) && (trak->strl) &&
             !strncmp(trak->strl->strf.bh.biCompression, "DIV3", 4))
       {
       strncpy(trak->strl->strh.fccHandler, "div3", 4);
       }
-    else if((codec->encoder->id == CODEC_ID_H263) &&
+    else if((codec->encoder->id == AV_CODEC_ID_H263) &&
             (file->file_type & (LQT_FILE_MP4|LQT_FILE_3GP)))
       {
       uint8_t d263_data[] =
@@ -1383,34 +1383,34 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
       strncpy(trak->mdia.minf.stbl.stsd.table[0].format,
               "s263", 4);
       }
-    else if(codec->encoder->id == CODEC_ID_FFVHUFF)
+    else if(codec->encoder->id == AV_CODEC_ID_FFVHUFF)
       {
       if(!(file->file_type & (LQT_FILE_AVI|LQT_FILE_AVI_ODML)))
         {
-        codec->avctx->flags |= CODEC_FLAG_GLOBAL_HEADER;
+        codec->avctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
         codec->write_global_header = 1;
         }
       }
-    else if(codec->encoder->id == CODEC_ID_QTRLE)
+    else if(codec->encoder->id == AV_CODEC_ID_QTRLE)
       {
       if(vtrack->stream_cmodel == BC_RGBA8888)
         {
         /* Libquicktime doesn't natively support a color model equivalent
-           to PIX_FMT_ARGB, which is required for QTRLE with alpha channel.
+           to AV_PIX_FMT_ARGB, which is required for QTRLE with alpha channel.
            So, we use BC_RGBA8888 and do ad hoc conversion below. */
-        codec->avctx->pix_fmt = PIX_FMT_ARGB;
+        codec->avctx->pix_fmt = AV_PIX_FMT_ARGB;
         vtrack->track->mdia.minf.stbl.stsd.table[0].depth = 32;
         }
       }
-    else if(codec->encoder->id == CODEC_ID_DVVIDEO)
+    else if(codec->encoder->id == AV_CODEC_ID_DVVIDEO)
       {
       set_dv_fourcc(width, height, vtrack->stream_cmodel, trak);
       }
-    else if(codec->encoder->id == CODEC_ID_DNXHD)
+    else if(codec->encoder->id == AV_CODEC_ID_DNXHD)
       {
       if(vtrack->interlace_mode != LQT_INTERLACE_NONE)
         {
-        codec->avctx->flags |= CODEC_FLAG_INTERLACED_DCT;
+        codec->avctx->flags |= AV_CODEC_FLAG_INTERLACED_DCT;
         }
       }
     else if(codec->is_imx)
@@ -1422,7 +1422,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
       if(codec->pass == 1)
         {
         codec->stats_file = fopen(codec->stats_filename, "w");
-        codec->avctx->flags |= CODEC_FLAG_PASS1;
+        codec->avctx->flags |= AV_CODEC_FLAG_PASS1;
         }
       else if(codec->pass == codec->total_passes)
         {
@@ -1438,7 +1438,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
         fclose(codec->stats_file);
         codec->stats_file = (FILE*)0;
               
-        codec->avctx->flags |= CODEC_FLAG_PASS2;
+        codec->avctx->flags |= AV_CODEC_FLAG_PASS2;
         }
       }
     /* Open codec */
@@ -1467,7 +1467,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
     }
   //        codec->lqt_colormodel = ffmepg_2_lqt(codec->com.ffcodec_enc);
 
-  if(codec->y_offset != 0 || codec->avctx->pix_fmt == PIX_FMT_ARGB)
+  if(codec->y_offset != 0 || codec->avctx->pix_fmt == AV_PIX_FMT_ARGB)
     {
     if(!codec->tmp_rows)
       {
@@ -1492,7 +1492,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
                         vtrack->stream_cmodel,
                         0, 0, 0, codec->y_offset);
       }
-    else if(codec->avctx->pix_fmt == PIX_FMT_ARGB)
+    else if(codec->avctx->pix_fmt == AV_PIX_FMT_ARGB)
       {
       convert_rgba_to_argb(row_pointers[0], vtrack->stream_row_span,
                            codec->tmp_rows[0], codec->tmp_row_span,
@@ -1516,7 +1516,7 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
     }
   
   codec->frame->pts = vtrack->timestamp;
-  if(codec->avctx->flags & CODEC_FLAG_QSCALE)
+  if(codec->avctx->flags & AV_CODEC_FLAG_QSCALE)
     codec->frame->quality = codec->qscale;
 #ifdef DO_INTERLACE
   if(vtrack->interlace_mode != LQT_INTERLACE_NONE)
@@ -1558,12 +1558,12 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
   
 #endif
   
-  if(!was_initialized && codec->encoder->id == CODEC_ID_DNXHD)
+  if(!was_initialized && codec->encoder->id == AV_CODEC_ID_DNXHD)
     setup_avid_atoms(file, vtrack, codec->buffer, bytes_encoded);
   
   if(bytes_encoded)
     {
-    if (pts == AV_NOPTS_VALUE || (codec->encoder->id == CODEC_ID_DNXHD && pts == 0))
+    if (pts == AV_NOPTS_VALUE || (codec->encoder->id == AV_CODEC_ID_DNXHD && pts == 0))
       {
       /* Some codecs don't bother generating presentation timestamps.
          FFMpeg's DNxHD encoder doesn't even bother to set it to AV_NOPTS_VALUE. */
@@ -1590,17 +1590,16 @@ static int lqt_ffmpeg_encode_video(quicktime_t *file, 
 
   if(codec->write_global_header && !codec->global_header_written)
     {
-    if(codec->encoder->id == CODEC_ID_FFVHUFF)
+    if(codec->encoder->id == AV_CODEC_ID_FFVHUFF)
       {
       quicktime_user_atoms_add_atom(&trak->mdia.minf.stbl.stsd.table[0].user_atoms,
                                     "glbl",
                                     codec->avctx->extradata, codec->avctx->extradata_size );
       }
-    else if(codec->encoder->id == CODEC_ID_MPEG4)
+    else if(codec->encoder->id == AV_CODEC_ID_MPEG4)
       {
       int advanced = 0;
-      if(codec->avctx->max_b_frames ||
-         (codec->avctx->flags & (CODEC_FLAG_QPEL|CODEC_FLAG_GMC)))
+      if(codec->avctx->max_b_frames)
         advanced = 1;
 
       setup_header_mpeg4(file, track, codec->avctx->extradata,
@@ -1903,18 +1902,18 @@ void quicktime_init_video_codec_ffmpeg(quicktime_codec
     codec_base->encode_video = lqt_ffmpeg_encode_video;
     codec_base->set_pass = set_pass_ffmpeg;
 
-    if(encoder->id == CODEC_ID_MPEG4)
+    if(encoder->id == AV_CODEC_ID_MPEG4)
       {
       codec_base->writes_compressed = writes_compressed_mpeg4;
       codec_base->init_compressed   = init_compressed_mpeg4;
       codec_base->write_packet = write_packet_mpeg4;
       }
-    else if(encoder->id == CODEC_ID_MPEG2VIDEO)
+    else if(encoder->id == AV_CODEC_ID_MPEG2VIDEO)
       {
       codec_base->writes_compressed = writes_compressed_imx;
       codec_base->init_compressed   = init_compressed_imx;
       }
-    else if(encoder->id == CODEC_ID_DVVIDEO)
+    else if(encoder->id == AV_CODEC_ID_DVVIDEO)
       {
       codec_base->init_compressed = init_compressed_dv;
       }
@@ -1922,7 +1921,7 @@ void quicktime_init_video_codec_ffmpeg(quicktime_codec
     }
   if(decoder)
     {
-    if(decoder->id == CODEC_ID_H264)
+    if(decoder->id == AV_CODEC_ID_H264)
       codec_base->read_packet = read_packet_h264;
     codec_base->decode_video = lqt_ffmpeg_decode_video;
     }
