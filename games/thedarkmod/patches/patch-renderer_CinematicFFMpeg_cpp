replace ExtLibs functions with system ones

Index: renderer/CinematicFFMpeg.cpp
--- renderer/CinematicFFMpeg.cpp.orig
+++ renderer/CinematicFFMpeg.cpp
@@ -77,7 +77,7 @@ static void LogPostMessage(const char *message) {
 
 void idCinematicFFMpeg::InitCinematic( void ) {
 	// Make sure all codecs are registered
-	ExtLibs::av_register_all();
+	av_register_all();
 
 	InvClockTicksPerSecond = 1.0 / idLib::sys->ClockTicksPerSecond();
 	//Note: we cannot init logfile, because we cannot read cvars yet (see constructor)
@@ -159,20 +159,20 @@ class idCinematicFFMpeg::VFSIOContext (public)
 		_bufferSize(4096),
 		_context(NULL)
 	{
-		unsigned char* buffer = static_cast<unsigned char*>(ExtLibs::av_malloc(_bufferSize));
+		unsigned char* buffer = static_cast<unsigned char*>(av_malloc(_bufferSize));
 		bool noseek = false;
 		if (_file->IsCompressed()) {
 			common->Warning("Opening video file \"%s\", which is compressed inside PK4.\n  Seeking function is disabled", _file->GetName());
 			noseek = true;
 		}
-		_context = ExtLibs::avio_alloc_context(buffer, _bufferSize, 0, this,
+		_context = avio_alloc_context(buffer, _bufferSize, 0, this,
 			&VFSIOContext::read, NULL, (noseek ? NULL : &VFSIOContext::seek));
 	}
 
 	~VFSIOContext()
 	{
-		ExtLibs::av_free(_context->buffer);
-		ExtLibs::av_free(_context);
+		av_free(_context->buffer);
+		av_free(_context);
 	}
 
 	static int read(void* opaque, unsigned char* buf, int buf_size)
@@ -240,11 +240,11 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 	LogPrintf("Opened file %s", _path.c_str());
 
 	if (r_cinematic_log_ffmpeg.GetBool())
-		ExtLibs::av_log_set_callback(idCinematicFFMpeg::LogCallback);
+		av_log_set_callback(idCinematicFFMpeg::LogCallback);
 
 	TIMER_START(ctxAlloc);
 	// Use libavformat to detect the video type and stream
-	_formatContext = ExtLibs::avformat_alloc_context();
+	_formatContext = avformat_alloc_context();
 	// To use the VFS we need to set up a custom AV I/O context
 	_customIOContext = new VFSIOContext(_file);
 	_formatContext->pb = _customIOContext->getContext();
@@ -252,11 +252,11 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 
 	TIMER_START(formatOpen);
 	AVDictionary *options = NULL;
-	//accelerate ExtLibs::avformat_find_stream_info by setting tighter limits
-	ExtLibs::av_dict_set_int(&options, "probesize", 1<<20, 0);
-	ExtLibs::av_dict_set_int(&options, "analyzeduration", int(1.0 * AV_TIME_BASE), 0);		//ROQ is bound by this one
-	bool ok = ExtLibs::avformat_open_input(&_formatContext, _path.c_str(), NULL, &options) >= 0;
-	ExtLibs::av_dict_free(&options);
+	//accelerate avformat_find_stream_info by setting tighter limits
+	av_dict_set_int(&options, "probesize", 1<<20, 0);
+	av_dict_set_int(&options, "analyzeduration", int(1.0 * AV_TIME_BASE), 0);		//ROQ is bound by this one
+	bool ok = avformat_open_input(&_formatContext, _path.c_str(), NULL, &options) >= 0;
+	av_dict_free(&options);
 	if (!ok) {
 		common->Warning("Could not open %s\n", _path.c_str());
 		return false;
@@ -264,7 +264,7 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 	TIMER_END_LOG(formatOpen, "AVFormat input opened");
 
 	TIMER_START(findStream);
-	if (ExtLibs::avformat_find_stream_info(_formatContext, NULL) < 0) {
+	if (avformat_find_stream_info(_formatContext, NULL) < 0) {
 		common->Warning("Could not find stream info %s\n", _path.c_str());
 		return false;
 	}
@@ -278,8 +278,8 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 	}
 	AVStream* videoStream = _formatContext->streams[_videoStreamIndex];
 	_videoDecoderContext = videoStream->codec;
-	AVRational videoTBase = ExtLibs::av_codec_get_pkt_timebase(_videoDecoderContext);
-	LogPrintf("Video stream timebase: %d/%d = %0.6lf", videoTBase.num, videoTBase.den, ExtLibs::av_q2d(videoTBase));
+	AVRational videoTBase = av_codec_get_pkt_timebase(_videoDecoderContext);
+	LogPrintf("Video stream timebase: %d/%d = %0.6lf", videoTBase.num, videoTBase.den, av_q2d(videoTBase));
 
 
 	if (_withAudio) {
@@ -291,13 +291,13 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 		}
 		AVStream* audioStream = _formatContext->streams[_audioStreamIndex];
 		_audioDecoderContext = audioStream->codec;
-		AVRational audioTBase = ExtLibs::av_codec_get_pkt_timebase(_audioDecoderContext);
-		LogPrintf("Audio stream timebase: %d/%d = %0.6lf", audioTBase.num, audioTBase.den, ExtLibs::av_q2d(audioTBase));
+		AVRational audioTBase = av_codec_get_pkt_timebase(_audioDecoderContext);
+		LogPrintf("Audio stream timebase: %d/%d = %0.6lf", audioTBase.num, audioTBase.den, av_q2d(audioTBase));
 	}
 
 	TIMER_START(createSwsCtx);
 	// Set up the scaling context used to convert the images to RGBA
-	_swScaleContext = ExtLibs::sws_getContext(
+	_swScaleContext = sws_getContext(
 		_videoDecoderContext->width, _videoDecoderContext->height,
 		_videoDecoderContext->pix_fmt,
 		_videoDecoderContext->width, _videoDecoderContext->height,
@@ -309,13 +309,13 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 	if (_withAudio) {
 		TIMER_START(createSwrCtx);
 		// Set up the scaling context used to convert the images to RGBA
-		_swResampleContext = ExtLibs::swr_alloc_set_opts(NULL,
+		_swResampleContext = swr_alloc_set_opts(NULL,
 			(_channels == 2 ? AV_CH_LAYOUT_STEREO : AV_CH_LAYOUT_MONO), AV_SAMPLE_FMT_FLT, FREQ44K,
 			_audioDecoderContext->channel_layout, _audioDecoderContext->sample_fmt, _audioDecoderContext->sample_rate,
 			0, _customIOContext
 		);
-		ExtLibs::swr_init(_swResampleContext);
-		if (!ExtLibs::swr_is_initialized(_swResampleContext)) {
+		swr_init(_swResampleContext);
+		if (!swr_is_initialized(_swResampleContext)) {
 			common->Warning("Could not initialize audio resample context for %s\n", _path.c_str());
 			return false;
 		}
@@ -325,24 +325,24 @@ bool idCinematicFFMpeg::_OpenDecoder() {
 		//but it is not part of decoder's data structures
 		//and it is NOT destroyed when decoder is closed
 		if (!_audioSamples._fifo) {
-			_audioSamples._fifo = ExtLibs::av_audio_fifo_alloc(AV_SAMPLE_FMT_FLT, _channels, FREQ44K);
+			_audioSamples._fifo = av_audio_fifo_alloc(AV_SAMPLE_FMT_FLT, _channels, FREQ44K);
 			_audioSamples._startTime = 0.0;
 		}
 	}
 
-	_tempVideoFrame = ExtLibs::av_frame_alloc();
+	_tempVideoFrame = av_frame_alloc();
 	if (_withAudio)
-		_tempAudioFrame = ExtLibs::av_frame_alloc();
+		_tempAudioFrame = av_frame_alloc();
 
 	//=== get some information we might need
 
 	// Some video formats (like the beloved ROQ) don't provider a sane duration value, so let's check
 	if (videoStream->duration != AV_NOPTS_VALUE && videoStream->duration >= 0)
-		_duration = videoStream->duration * ExtLibs::av_q2d(videoStream->time_base);
+		_duration = videoStream->duration * av_q2d(videoStream->time_base);
 	else
 		_duration = 100.000; // use a hardcoded value, just like the good old idCinematicLocal
 
-	_frameRate = ExtLibs::av_q2d(_videoDecoderContext->framerate);
+	_frameRate = av_q2d(_videoDecoderContext->framerate);
 
 	_framebufferWidth = _videoDecoderContext->width;
 	_framebufferHeight = _videoDecoderContext->height;
@@ -364,32 +364,32 @@ void idCinematicFFMpeg::CloseDecoder() {
 	while (DropPacket(_audioPackets));
 
 	if (_tempVideoFrame)
-		ExtLibs::av_frame_free(&_tempVideoFrame);
+		av_frame_free(&_tempVideoFrame);
 	_tempVideoFrame = NULL;
 	if (_tempAudioFrame)
-		ExtLibs::av_frame_free(&_tempAudioFrame);
+		av_frame_free(&_tempAudioFrame);
 	_tempAudioFrame = NULL;
 
 	_videoStreamIndex = -1;
 	_audioStreamIndex = -1;
 
 	if (_swScaleContext)
-		ExtLibs::sws_freeContext(_swScaleContext);
+		sws_freeContext(_swScaleContext);
 	_swScaleContext = NULL;
 	if (_swResampleContext)
-		ExtLibs::swr_free(&_swResampleContext);
+		swr_free(&_swResampleContext);
 	_swResampleContext = NULL;
 
 	if (_videoDecoderContext)
-		ExtLibs::avcodec_close(_videoDecoderContext);
+		avcodec_close(_videoDecoderContext);
 	_videoDecoderContext = NULL;
 
 	if (_audioDecoderContext)
-		ExtLibs::avcodec_close(_audioDecoderContext);
+		avcodec_close(_audioDecoderContext);
 	_audioDecoderContext = NULL;
 
 	if (_formatContext)
-		ExtLibs::avformat_close_input(&_formatContext);
+		avformat_close_input(&_formatContext);
 	_formatContext = NULL;
 
 	if (_customIOContext)
@@ -405,21 +405,21 @@ void idCinematicFFMpeg::CloseDecoder() {
 
 int idCinematicFFMpeg::OpenBestStreamOfType(AVMediaType type) {
 	TIMER_START(findBestStream);
-	int streamIndex = ExtLibs::av_find_best_stream(_formatContext, type, -1, -1, NULL, 0);
+	int streamIndex = av_find_best_stream(_formatContext, type, -1, -1, NULL, 0);
 	if (streamIndex < 0) {
-		common->Warning("Could not find %s stream in input.\n", ExtLibs::av_get_media_type_string(type));
+		common->Warning("Could not find %s stream in input.\n", av_get_media_type_string(type));
 		return -1;
 	}
 	TIMER_END_LOG(findBestStream, "Found best stream");
 	AVStream* st = _formatContext->streams[streamIndex];
 
 	AVCodecID codecId = st->codec->codec_id;
-	LogPrintf("Stream %d is encoded with codec %d: %s", streamIndex, codecId, ExtLibs::avcodec_get_name(codecId));
+	LogPrintf("Stream %d is encoded with codec %d: %s", streamIndex, codecId, avcodec_get_name(codecId));
 	// find decoder for the stream
 	TIMER_START(findDecoder);
-	AVCodec* dec = ExtLibs::avcodec_find_decoder(codecId);
+	AVCodec* dec = avcodec_find_decoder(codecId);
 	if (!dec) {
-		common->Warning("Failed to find %s:%s decoder\n", ExtLibs::av_get_media_type_string(type), ExtLibs::avcodec_get_name(codecId));
+		common->Warning("Failed to find %s:%s decoder\n", av_get_media_type_string(type), avcodec_get_name(codecId));
 		return AVERROR(EINVAL);
 	}
 	TIMER_END_LOG(findDecoder, "Found decoder");
@@ -433,8 +433,8 @@ int idCinematicFFMpeg::OpenBestStreamOfType(AVMediaTyp
 
 	TIMER_START(openCodec);
 	AVDictionary *opts = NULL;
-	if (ExtLibs::avcodec_open2(st->codec, dec, &opts) < 0) {
-		common->Warning("Failed to open %s:%s codec\n", ExtLibs::av_get_media_type_string(type), ExtLibs::avcodec_get_name(codecId));
+	if (avcodec_open2(st->codec, dec, &opts) < 0) {
+		common->Warning("Failed to open %s:%s codec\n", av_get_media_type_string(type), avcodec_get_name(codecId));
 		return -1;
 	}
 	TIMER_END_LOG(openCodec, "Opened decoder");
@@ -448,30 +448,30 @@ bool idCinematicFFMpeg::FetchPacket() {
 	while (true) {
 		TIMER_START(readPacket);
 		AVPacket newPacket;
-		ExtLibs::av_init_packet(&newPacket);
-		int ret = ExtLibs::av_read_frame(_formatContext, &newPacket);
+		av_init_packet(&newPacket);
+		int ret = av_read_frame(_formatContext, &newPacket);
 		if (ret < 0) {
-			ExtLibs::av_packet_unref(&newPacket);
+			av_packet_unref(&newPacket);
 			return false;
 		}
 		TIMER_END_LOG(readPacket, "Read packet");
 
 		int stream = newPacket.stream_index;
 		AVStream* st = _formatContext->streams[stream];
-		AVMediaType type = ExtLibs::avcodec_get_type(st->codec->codec_id);
+		AVMediaType type = avcodec_get_type(st->codec->codec_id);
 		LogPrintf("Packet: stream = %d (%s)  size = %d  DTS = %lld  PTS = %lld  dur = %d",
-			newPacket.stream_index, ExtLibs::av_get_media_type_string(type), newPacket.size,
+			newPacket.stream_index, av_get_media_type_string(type), newPacket.size,
 			newPacket.dts, newPacket.pts, newPacket.duration
 		);
 
 		if (stream != _videoStreamIndex && stream != _audioStreamIndex) {
-			ExtLibs::av_packet_unref(&newPacket);
+			av_packet_unref(&newPacket);
 			continue;
 		}
 
 		PacketQueue &queue = (stream == _videoStreamIndex ? _videoPackets : _audioPackets);
 		AVPacketList *packetNode = new AVPacketList();
-		ExtLibs::av_packet_move_ref(&packetNode->pkt, &newPacket);
+		av_packet_move_ref(&packetNode->pkt, &newPacket);
 		queue.Add(packetNode);
 
 		return ret >= 0;
@@ -500,7 +500,7 @@ bool idCinematicFFMpeg::DropPacket(PacketQueue &queue)
 
 void idCinematicFFMpeg::FreePacket(AVPacketList *packetNode) {
 	if (!packetNode) return;
-	ExtLibs::av_packet_unref(&packetNode->pkt);
+	av_packet_unref(&packetNode->pkt);
 	delete packetNode;
 }
 
@@ -562,11 +562,11 @@ int idCinematicFFMpeg::DecodePacket(AVMediaType type, 
 		int gotFrame = 0;
 		int readBytes;
 		if (type == AVMEDIA_TYPE_VIDEO)
-			readBytes = ExtLibs::avcodec_decode_video2(_videoDecoderContext, _tempVideoFrame, &gotFrame, &packet);
+			readBytes = avcodec_decode_video2(_videoDecoderContext, _tempVideoFrame, &gotFrame, &packet);
 		else		//AVMEDIA_TYPE_AUDIO
-			readBytes = ExtLibs::avcodec_decode_audio4(_audioDecoderContext, _tempAudioFrame, &gotFrame, &packet);
+			readBytes = avcodec_decode_audio4(_audioDecoderContext, _tempAudioFrame, &gotFrame, &packet);
 		if (readBytes < 0) {
-			common->Warning("Error decoding %s frame (%d)\n", ExtLibs::av_get_media_type_string(type), readBytes);
+			common->Warning("Error decoding %s frame (%d)\n", av_get_media_type_string(type), readBytes);
 			return false;
 		}
 		TIMER_END_LOG(decode, "Packet decoded");
@@ -585,9 +585,9 @@ int idCinematicFFMpeg::DecodePacket(AVMediaType type, 
 
 void idCinematicFFMpeg::ProcessDecodedFrame(AVMediaType type, AVFrame *decodedFrame, double discardTime) {
 	//determine good timestamp using FFmpeg magic
-	int64_t pts = ExtLibs::av_frame_get_best_effort_timestamp(decodedFrame);
+	int64_t pts = av_frame_get_best_effort_timestamp(decodedFrame);
 	int streamIdx = (type == AVMEDIA_TYPE_VIDEO ? _videoStreamIndex : _audioStreamIndex);
-	double timebase = ExtLibs::av_q2d(_formatContext->streams[streamIdx]->time_base);
+	double timebase = av_q2d(_formatContext->streams[streamIdx]->time_base);
 	double duration = decodedFrame->pkt_duration * timebase;
 	double framestart = pts * timebase;
 	framestart += _loopNumber * _loopDuration;
@@ -596,7 +596,7 @@ void idCinematicFFMpeg::ProcessDecodedFrame(AVMediaTyp
 	//otherwise a pause in playback may cause a lot of frames to
 	//be decoded immediately, eating much memory
 	if (framestart + duration < discardTime) {
-		LogPrintf("Discarded %s frame with timestamp: %0.3lf + %0.3lf  (sec)", ExtLibs::av_get_media_type_string(type), framestart, duration);
+		LogPrintf("Discarded %s frame with timestamp: %0.3lf + %0.3lf  (sec)", av_get_media_type_string(type), framestart, duration);
 		return;
 	}
 
@@ -627,7 +627,7 @@ void idCinematicFFMpeg::ProcessDecodedVideoFrame(AVFra
 	// That's why swscale expects only single destination pointer + stride
 	uint8_t* const dstPtr[1] = { frame->_image };
 	int lineWidth[1] = { _videoDecoderContext->width * 4 };
-	ExtLibs::sws_scale(
+	sws_scale(
 		_swScaleContext,
 		decodedFrame->data, decodedFrame->linesize, 0, decodedFrame->height,
 		dstPtr, lineWidth
@@ -691,9 +691,9 @@ void idCinematicFFMpeg::DestroyAllFrames() {
 
 void idCinematicFFMpeg::ProcessDecodedAudioFrame(AVFrame *decodedFrame, double timestamp, double duration) {
 	//put sound samples into internal buffer of swResample
-	int decodedSamples = ExtLibs::swr_convert_frame(_swResampleContext, NULL, decodedFrame);
+	int decodedSamples = swr_convert_frame(_swResampleContext, NULL, decodedFrame);
 
-	int beforeCnt = ExtLibs::av_audio_fifo_size(_audioSamples._fifo);
+	int beforeCnt = av_audio_fifo_size(_audioSamples._fifo);
 	double newStartTime = timestamp - beforeCnt / double(FREQ44K);
 	if (fabs(newStartTime - _audioSamples._startTime) > TIMESTAMP_JITTER_TOLERANCE)
 		_audioSamples._startTime = newStartTime;
@@ -704,13 +704,13 @@ void idCinematicFFMpeg::ProcessDecodedAudioFrame(AVFra
 
 		TIMER_START(swrResample);
 		uint8_t* dstPtr = (uint8_t*)buff;
-		int moreSamples = ExtLibs::swr_convert(_swResampleContext, &dstPtr, BuffSize, NULL, 0);
+		int moreSamples = swr_convert(_swResampleContext, &dstPtr, BuffSize, NULL, 0);
 		if (moreSamples == 0)
 			break;
 		SIMDProcessor->Mul(buff, 32767.0f, buff, _channels * moreSamples);
 		TIMER_END_LOG(swrResample, "Converted sound samples");
 
-		int cnt = ExtLibs::av_audio_fifo_write(_audioSamples._fifo, (void**)&dstPtr, moreSamples);
+		int cnt = av_audio_fifo_write(_audioSamples._fifo, (void**)&dstPtr, moreSamples);
 		assert(cnt == moreSamples);
 		decodedSamples += moreSamples;
 	}
@@ -720,7 +720,7 @@ void idCinematicFFMpeg::ProcessDecodedAudioFrame(AVFra
 
 bool idCinematicFFMpeg::GetAudioInterval(double videoTime, int samplesCount, float *output) {
 	while (true) {
-		double fifoEndTime = _audioSamples._startTime + ExtLibs::av_audio_fifo_size(_audioSamples._fifo) / double(FREQ44K);
+		double fifoEndTime = _audioSamples._startTime + av_audio_fifo_size(_audioSamples._fifo) / double(FREQ44K);
 		double reqEndTime = videoTime + (samplesCount + 3) / double(FREQ44K) + TIMESTAMP_JITTER_TOLERANCE;
 		if (fifoEndTime >= reqEndTime)
 			break;
@@ -733,7 +733,7 @@ bool idCinematicFFMpeg::GetAudioInterval(double videoT
 	if (rngStart >= 0.0) {
 		int drop = int(rngStart + 0.5);
 		if (drop > 0) {
-			ExtLibs::av_audio_fifo_drain(_audioSamples._fifo, drop);
+			av_audio_fifo_drain(_audioSamples._fifo, drop);
 			_audioSamples._startTime += drop / double(FREQ44K);
 			LogPrintf("Dropped %d sound samples", drop);
 		}
@@ -743,14 +743,14 @@ bool idCinematicFFMpeg::GetAudioInterval(double videoT
 		if (insert > 0) {
 			float fill[2] = {0, 0};
 			//TODO: use this code with newer FFmpeg
-			/*if (ExtLibs::av_audio_fifo_size(_audioSamples._fifo) > 0) {
+			/*if (av_audio_fifo_size(_audioSamples._fifo) > 0) {
 				float *ptr = fill;
-				ExtLibs::av_audio_fifo_peek(_audioSamples._fifo, (void**)&ptr, 1);
+				av_audio_fifo_peek(_audioSamples._fifo, (void**)&ptr, 1);
 			}*/
 			//TODO: remove this crap with newer ffmpeg
-			assert(ExtLibs::av_audio_fifo_size(_audioSamples._fifo) > 0);
+			assert(av_audio_fifo_size(_audioSamples._fifo) > 0);
 			float *ptr = fill;
-			if (ExtLibs::av_audio_fifo_read(_audioSamples._fifo, (void**)&ptr, 1)) {
+			if (av_audio_fifo_read(_audioSamples._fifo, (void**)&ptr, 1)) {
 				_audioSamples._startTime += 1.0 / FREQ44K;
 				insert++;
 			}
@@ -767,7 +767,7 @@ bool idCinematicFFMpeg::GetAudioInterval(double videoT
 			return true;
 	}
 
-	int read = ExtLibs::av_audio_fifo_read(_audioSamples._fifo, (void**)&output, samplesCount);
+	int read = av_audio_fifo_read(_audioSamples._fifo, (void**)&output, samplesCount);
 	assert(read == samplesCount);
 	_audioSamples._startTime += samplesCount / double(FREQ44K);
 
@@ -776,16 +776,16 @@ bool idCinematicFFMpeg::GetAudioInterval(double videoT
 
 void idCinematicFFMpeg::DiscardOldSamples(double videoTime) {
 	int drop = int((videoTime - _audioSamples._startTime - TIMESTAMP_JITTER_TOLERANCE) * FREQ44K);
-	drop = idMath::Imin(drop, ExtLibs::av_audio_fifo_size(_audioSamples._fifo));
+	drop = idMath::Imin(drop, av_audio_fifo_size(_audioSamples._fifo));
 	if (drop > 0) {
-		ExtLibs::av_audio_fifo_drain(_audioSamples._fifo, drop);
+		av_audio_fifo_drain(_audioSamples._fifo, drop);
 		_audioSamples._startTime += drop / double(FREQ44K);
 	}
 }
 
 void idCinematicFFMpeg::DestroyAllSamples() {
 	if (_audioSamples._fifo)
-		ExtLibs::av_audio_fifo_free(_audioSamples._fifo);
+		av_audio_fifo_free(_audioSamples._fifo);
 	_audioSamples._fifo = NULL;
 	_audioSamples._startTime = DBL_MAX;
 }
